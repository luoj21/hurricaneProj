{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2c17742",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cc18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import haversine as hs\n",
    "from haversine import haversine, Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079d25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning data into csv format\n",
    "\n",
    "# Read a table of fixed-width formatted lines into DataFrame.\n",
    "df1 = pd.read_fwf(\"atlantic.txt\")\n",
    "df2 = pd.read_fwf(\"central_north_pacific.txt\")\n",
    "df3 = pd.read_fwf(\"eastern_north_pacific.txt\")\n",
    "\n",
    "df1.to_csv(\"atlantic.csv\", index = None)\n",
    "df2.to_csv(\"central_north_pacific.txt.csv\", index = None)\n",
    "df3.to_csv(\"eastern_north_pacific.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae111db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing csv files\n",
    "atl = pd.read_csv(\"atlantic.csv\", header = None)\n",
    "central = pd.read_csv(\"central_north_pacific.txt.csv\", header = None)\n",
    "eastern = pd.read_csv(\"eastern_north_pacific.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ccf467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names\n",
    "colnames = ['SID', 'name', 'm/d/t', 'year', 'lat', 'long', 'maxwind', 'min_cp', 'rad_maxwind',\n",
    "               'eye_diam', 'pressure_isobar', 'rad_isobar', 'radii34', 'radii50', 'radii64', 'stormtype', 'dtl', 'source_data']\n",
    "\n",
    "atl.columns = colnames\n",
    "central.columns = colnames\n",
    "eastern.columns = colnames\n",
    "\n",
    "#all_data = pd.concat([atl, central, pacific], axis = 0).reset_index(drop=True)\n",
    "\n",
    "# For info on data documention, see https://rammb2.cira.colostate.edu/research/tropical-cyclones/tc_extended_best_track_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed85d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df):\n",
    "    # Converting to datetime format \n",
    "    df['m/d/t'] = df['m/d/t'].astype(str)\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['m/d/t'] = ['0' + mdt if len(mdt) < 6 else mdt for mdt in df['m/d/t']]\n",
    "    df['date_time'] = df['year'] + df['m/d/t']\n",
    "    df['date_time'] = [datetime.strptime(dt, '%Y%m%d%H') for dt in df['date_time']]\n",
    "\n",
    "    df.drop(columns = ['m/d/t', 'year'], inplace = True)\n",
    "    \n",
    "    # Turning instances where -99 shows up to None\n",
    "    df['min_cp'] = [None if str(data).startswith(str(-99)) else data for data in df['min_cp']]\n",
    "    df['rad_maxwind'] = [None if str(data).startswith(str(-99)) else data for data in df['rad_maxwind']]\n",
    "    df['eye_diam'] = [None if str(data).startswith(str(-99)) else data for data in df['eye_diam']]\n",
    "    df['pressure_isobar'] = [None if str(data).startswith(str(-99)) else data for data in df['pressure_isobar']]\n",
    "    df['rad_isobar'] = [None if str(data).startswith(str(-99)) else data for data in df['rad_isobar']]\n",
    "    df['maxwind'] = [None if str(data).startswith(str(-99)) else data for data in df['maxwind']]\n",
    "\n",
    "    # Renaming 1 stormtype\n",
    "    df['stormtype'] = ['Sys' if data == '*' else data for data in df['stormtype']]\n",
    "\n",
    "    # Deleting other columns\n",
    "    df.drop(columns  = ['radii34', 'radii50', 'radii64', 'source_data'], inplace = True)\n",
    "    df = df[df['lat'].between(-90,90)] # removing impossible long lat values\n",
    "    df = df[df['long'].between(-180,180)]\n",
    "    df['distance'] = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab74d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl = cleanData(atl)\n",
    "eastern = cleanData(eastern)\n",
    "central = cleanData(central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa996742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>maxwind</th>\n",
       "      <th>min_cp</th>\n",
       "      <th>rad_maxwind</th>\n",
       "      <th>eye_diam</th>\n",
       "      <th>pressure_isobar</th>\n",
       "      <th>rad_isobar</th>\n",
       "      <th>stormtype</th>\n",
       "      <th>dtl</th>\n",
       "      <th>date_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>AL01</td>\n",
       "      <td>28.0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sys</td>\n",
       "      <td>111</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>AL01</td>\n",
       "      <td>28.0</td>\n",
       "      <td>95.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sys</td>\n",
       "      <td>79</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>AL01</td>\n",
       "      <td>28.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sys</td>\n",
       "      <td>59</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>AL01</td>\n",
       "      <td>28.1</td>\n",
       "      <td>96.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sys</td>\n",
       "      <td>17</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>AL01</td>\n",
       "      <td>28.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sys</td>\n",
       "      <td>-23</td>\n",
       "      <td>1851-06-26 00:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID  name   lat  long  maxwind  min_cp  rad_maxwind  eye_diam  \\\n",
       "0  AL011851  AL01  28.0  94.8     80.0     NaN          NaN       NaN   \n",
       "1  AL011851  AL01  28.0  95.4     80.0     NaN          NaN       NaN   \n",
       "2  AL011851  AL01  28.0  96.0     80.0     NaN          NaN       NaN   \n",
       "3  AL011851  AL01  28.1  96.5     80.0     NaN          NaN       NaN   \n",
       "4  AL011851  AL01  28.2  97.0     70.0     NaN          NaN       NaN   \n",
       "\n",
       "   pressure_isobar  rad_isobar stormtype  dtl           date_time distance  \n",
       "0              NaN         NaN       Sys  111 1851-06-25 00:00:00     None  \n",
       "1              NaN         NaN       Sys   79 1851-06-25 06:00:00     None  \n",
       "2              NaN         NaN       Sys   59 1851-06-25 12:00:00     None  \n",
       "3              NaN         NaN       Sys   17 1851-06-25 18:00:00     None  \n",
       "4              NaN         NaN       Sys  -23 1851-06-26 00:00:00     None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c4e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lat2, lon1, lon2):\n",
    "    p1 = (lat1, lon1)\n",
    "    p2 = (lat2, lon2)\n",
    "    \n",
    "    return hs.haversine(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcad20ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillDictionary(data):\n",
    "\n",
    "    dict = {key: None for key in pd.unique(data['SID'])}\n",
    "\n",
    "    # Filling initial dictionary with hurricanes\n",
    "    for key in dict.keys():\n",
    "        dict[key] = data[:][data['SID'] == key]\n",
    "        dict[key].reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # Feature engineering on each df\n",
    "    # Creating distance and cummulative distance\n",
    "    for key in dict.keys():\n",
    "        dict[key].loc[0, 'distance'] = 0\n",
    "    \n",
    "        for i in range(1, len(dict[key])):\n",
    "            dict[key].loc[i, 'distance'] = haversine(dict[key].iloc[i-1, :]['lat'], \n",
    "                                                     dict[key].iloc[i, :]['lat'], \n",
    "                                                     dict[key].iloc[i-1, :]['long'], \n",
    "                                                     dict[key].iloc[i, :]['long'])\n",
    "            dict[key]['cum_distance'] = np.cumsum(dict[key]['distance'])\n",
    "\n",
    "\n",
    "\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e896ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_dict = fillDictionary(atl)\n",
    "eastern_dict = fillDictionary(eastern)\n",
    "central_dict = fillDictionary(central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a336049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToDf(dictionary):\n",
    "    df_list = [dictionary[key] for key in dictionary.keys()]\n",
    "    \n",
    "    return pd.concat(df_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_preproc = dictToDf(atl_dict)\n",
    "eastern_preproc = dictToDf(eastern_dict)\n",
    "central_preproc = dictToDf(central_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_preproc.to_csv('central_preproc.csv', index_label=False)\n",
    "eastern_preproc.to_csv('eastern_preproc.csv', index_label=False)\n",
    "atl_preproc.to_csv('atl_preproc.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
